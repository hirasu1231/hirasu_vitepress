import{_ as o,c,j as l,a as p,G as a,w as s,ag as i,B as n,o as h}from"./chunks/framework.BDI6Vt0-.js";const C=JSON.parse('{"title":"CycleGANの概要","description":"CycleGANの概要を記述します．","frontmatter":{"title":"CycleGANの概要","description":"CycleGANの概要を記述します．","date":"2021-12-19T00:00:00.000Z","category":["Python"],"tags":["Python","Jupyter","CycleGAN","GAN"]},"headers":[],"relativePath":"posts/cyclegan04.md","filePath":"posts/cyclegan04.md"}'),d={name:"posts/cyclegan04.md"};function m(A,e,y,N,_,u){const t=n("CallInArticleAdsense"),r=n("ClientOnly");return h(),c("div",null,[e[0]||(e[0]=l("p",null,[p("CycleGANの概要を記述します．"),l("br")],-1)),a(r,null,{default:s(()=>[a(t)]),_:1}),e[1]||(e[1]=i('<h2 id="gan-敵対的生成ネットワーク-の概要" tabindex="-1">GAN（敵対的生成ネットワーク）の概要 <a class="header-anchor" href="#gan-敵対的生成ネットワーク-の概要" aria-label="Permalink to &quot;GAN（敵対的生成ネットワーク）の概要&quot;">​</a></h2><p>GAN（敵対的生成ネットワーク）は2014年に提案された画像生成モデルで、これをきっかけに画像生成モデルは大きな発展を遂げました。 GANでは、偽のデータを生成するGenerator (生成モデル)と、データが本物か偽物かを判別するDiscriminator (識別モデル)を敵対するように競わせることで互いの性能が向上するように学習します。</p><p>GANの仕組みは、贋作を作る犯罪者とそれを見破る警察官の関係に例えられます。 犯罪者は本物そっくりの贋作を作ることを目指して訓練し、警察官は必ず贋作を見破れるよう訓練します。 この敵対した競争により、犯罪者は本物そっくりの贋作を作れるようになります。</p><p>GANでは、上記の性質を利用して優秀な犯罪者(Generator)を育て上げ、贋作(新たな画像)を作成します。</p><h2 id="cycleganについて" tabindex="-1">CycleGANについて <a class="header-anchor" href="#cycleganについて" aria-label="Permalink to &quot;CycleGANについて&quot;">​</a></h2><p>CycleGANは、画像生成・画像スタイル変換で用いられるGAN（敵対的生成ネットワーク）の1つで、画像の相互変換する事が可能なモデルです。 CycleGANの登場以前ではpix2pixというモデルが有名でしたが、学習データを変換前と変換後でペアになるようにする必要がありました。(下図参照) !(<a href="https://api.axross-recipe.com/attachments/5255/url" target="_blank" rel="noreferrer">https://api.axross-recipe.com/attachments/5255/url</a>)</p><p>しかし、CycleGANでは変換前と変換後の画像間で「何らかの関係がある」と仮定して、「画像間で関係ある領域を特定した上で、その領域内での対応関係」を学習します。</p><p>!(<a href="https://api.axross-recipe.com/attachments/5288/url" target="_blank" rel="noreferrer">https://api.axross-recipe.com/attachments/5288/url</a>)</p><p>よって、学習データをペアとする必要がなくなり、学習データを準備する手間が一気に簡単になりました。</p><p>本レシピの学習データは、ペアとならない異なる白黒画像とカラー画像を準備します。 !(<a href="https://api.axross-recipe.com/attachments/5257/url" target="_blank" rel="noreferrer">https://api.axross-recipe.com/attachments/5257/url</a>)</p><h2 id="ペアを必要としない理由" tabindex="-1">ペアを必要としない理由 <a class="header-anchor" href="#ペアを必要としない理由" aria-label="Permalink to &quot;ペアを必要としない理由&quot;">​</a></h2><p>ウマとシマウマのデータセットを例とすると、CycleGANは「ウマ→シマウマ」の変換モデルAと「シマウマ→ウマ」の変換モデルBの両方を作成しています。 CycleGANでは、この2つの変換モデルを使って、「ウマ→シマウマ→ウマ(or シマウマ→ウマ→シマウマ)」という変換後に元に戻す復元作業も実行しています。</p><p>ペアの画像では変換したピクセルの箇所に着目すれば簡単に復元できますが、CycleGANでは「ペアではないデータ」で変換モデルA・Bを作成しているため、「画像中で変換した領域」の特徴(ここでは馬の形)を掴まなければ復元できません。 この復元作業により「画像間で関係ある領域の特定」を学習できるため、学習画像データをペアとする必要がなくなります。</p><p>!(<a href="https://api.axross-recipe.com/attachments/5290/url" target="_blank" rel="noreferrer">https://api.axross-recipe.com/attachments/5290/url</a>)</p><p>この学習方法によりCycleGANではいくつかのloss(学習時の評価指標)のうち、変換後に復元具合を評価する「Cycle Consistency Loss」が最も重要となります。</p><h2 id="まとめ" tabindex="-1">まとめ <a class="header-anchor" href="#まとめ" aria-label="Permalink to &quot;まとめ&quot;">​</a></h2><p>Python + CycleGanでオリジナルデータでの学習について，追加情報を記述しました．</p><h2 id="参考サイト" tabindex="-1">参考サイト <a class="header-anchor" href="#参考サイト" aria-label="Permalink to &quot;参考サイト&quot;">​</a></h2><p><a href="https://blog.negativemind.com/2019/06/22/generative-adversarial-networks/" target="_blank" rel="noreferrer">GAN (Generative Adversarial Networks)：敵対的生成ネットワーク</a></p>',19)),a(r,null,{default:s(()=>[a(t)]),_:1})])}const f=o(d,[["render",m]]);export{C as __pageData,f as default};
